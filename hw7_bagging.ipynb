{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMms33J4jeDZ"
   },
   "source": [
    "1. Use any binary classification dataset\n",
    "2. Define validation strategy and use it for all next steps without changes\n",
    "3. Train decision tree model and estimate performance on validation\n",
    "4. Train bagging model with decision tree as a base model and estimate performance on validation\n",
    "5. Write your own bagging implementation:\n",
    "  <br>5.1. Define init for our CustomBaggingClassifier\n",
    "  <br>5.2. Write fit as described in lecture: divide train data on n parts (`n_estimators` in CustomBaggingClassifier), train `base_estimator` on each part and save these models inside class\n",
    "  <br>5.3. For predictions we should use all saved models and combine their predictions (as voting)\n",
    "6. Compare performance of sklearn bagging model with your own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/spaceship_titanic_train.csv')\n",
    "test = pd.read_csv('../data/spaceship_titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    group_count = lambda id_: id_[:4]\n",
    "    data['travel_group'] = data['PassengerId'].apply(lambda id_: id_[:4])\n",
    "    data['travel_group_n'] = data['travel_group'].apply(lambda group: data.loc[data.travel_group == group].shape[0])\n",
    "    data['travelling_with_n_kids'] = (-1)*(train['Age'] < 18).astype(int)+ data['travel_group'].apply(lambda group: data.loc[(data.travel_group == group) & (data.Age < 18)].shape[0])\n",
    "    data['cabin_side'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else str(cabin)[-1])\n",
    "    data['cabin_deck'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else str(cabin)[0])\n",
    "    data['cabin_num'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else int(str(cabin)[2:-2]))\n",
    "    \n",
    "    \n",
    "    drop_ = ['PassengerId','Name', 'Cabin', 'travel_group']\n",
    "    cat = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Transported', 'cabin_side', 'cabin_deck']\n",
    "    num = ['FoodCourt', 'VRDeck', 'Spa', 'Age', 'RoomService', 'ShoppingMall', 'cabin_num']\n",
    "    one_hot = OneHotEncoder(sparse_output=False, drop='if_binary')\n",
    "    \n",
    "    pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    one_hot)\n",
    "    \n",
    "    transformer = ColumnTransformer([\n",
    "        ('cat', pipe, cat),\n",
    "        ('num', SimpleImputer(strategy='mean'), num),\n",
    "        ('drop_', 'drop', drop_)\n",
    "    ], remainder='passthrough',\n",
    "       verbose_feature_names_out=False)\n",
    "\n",
    "    \n",
    "    d = transformer.fit_transform(data)\n",
    "    \n",
    "    df = pd.DataFrame(d, columns = transformer.get_feature_names_out(), dtype=float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = prepare_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "# report = ProfileReport(train_prep, explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_prep.drop('Transported_True', axis=1), train_prep.Transported_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              criterion=&#x27;entropy&#x27;),\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [None, 10, 20, 50, 100],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 15, 20, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              criterion=&#x27;entropy&#x27;),\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [None, 10, 20, 50, 100],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 15, 20, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              criterion='entropy'),\n",
       "             param_grid={'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'max_leaf_nodes': [None, 10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 5, 10, 15, 20, 30]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(class_weight='balanced', criterion='entropy')\n",
    "\n",
    "params = {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          'min_samples_leaf': [1, 5, 10, 15, 20, 30],\n",
    "          'max_leaf_nodes': [None, 10, 20, 50, 100]}\n",
    "grid = GridSearchCV(tree, params, cv=5, scoring='accuracy', verbose=0)\n",
    "grid.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "                        max_depth=10, max_leaf_nodes=50, min_samples_leaf=30),\n",
       " 0.7824710443616988)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone, BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython import display\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ZSixk8wXjZJZ"
   },
   "outputs": [],
   "source": [
    "class CustomBaggingClassifier(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, base_estimator=DecisionTreeClassifier(), n_estimators=10, max_samples=0.9, max_features=0.7, random_state=127):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.bag = []\n",
    "        features = X.columns\n",
    "        n_rows = X.shape[0]\n",
    "        self.max_samples = self.max_samples if (self.max_samples % 1 == 0) else max(1, int(self.max_samples*n_rows))\n",
    "        self.max_features = self.max_features if (self.max_features % 1 == 0) else max(1, int(self.max_features*len(features)))\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            bootstrap_set = X.sample(n=self.max_samples, replace=True, axis='index', random_state=(self.random_state+i)).sample(n=self.max_features, replace=False, axis='columns', random_state=(self.random_state+i))\n",
    "            bootstrap_y = y.iloc[bootstrap_set.index]\n",
    "            #\n",
    "            bootstrap_set.reset_index(inplace=True, drop=True)\n",
    "            bootstrap_y.reset_index(inplace=True, drop=True)\n",
    "            #\n",
    "            ith_estimator = clone(self.base_estimator)\n",
    "            ith_estimator.fit(bootstrap_set, bootstrap_y)\n",
    "            self.bag+=[ith_estimator]   \n",
    "        return  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        preds = np.zeros((X.shape[0], self.n_classes))\n",
    "        for estimator in self.bag:\n",
    "            X_seen_features = X[estimator.feature_names_in_]\n",
    "            preds += estimator.predict_proba(X_seen_features)\n",
    "       # f = lambda p: 1 if p/self.n_estimators > 0.5 else 0\n",
    "        f = lambda a: np.argmax(a, axis=1)\n",
    "       # activate = np.vectorize(f)\n",
    "       # return activate(preds)\n",
    "        return f(preds)\n",
    "     \n",
    "    def look_up_importances(self):\n",
    "        i = 1\n",
    "        for estimator in self.bag:\n",
    "            importances = list(zip(estimator.feature_names_in_,estimator.feature_importances_))\n",
    "            importances.sort(key=lambda x: x[1], reverse=True)\n",
    "            print('estimator: ' + str(i))\n",
    "            for im in importances:\n",
    "                print(im)\n",
    "            i+=1    \n",
    "            print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation:\n",
    "    def __init__(self, data, estimator, params, random_state=127):\n",
    "        self.data = data\n",
    "        self.estimator = estimator\n",
    "        self.params = params\n",
    "        self.random_state = random_state\n",
    "           \n",
    "    def build_param_grid(self):\n",
    "        first_key = list(self.params.keys())[0]\n",
    "        dots = []\n",
    "        \n",
    "        values = self.params.pop(first_key)\n",
    "        if (params):\n",
    "            for dot in self.build_param_grid():\n",
    "                for value in values:\n",
    "                    dot_copy = dot.copy()\n",
    "                    dot_copy[first_key] = value\n",
    "                    dots.append(dot_copy)\n",
    "            return dots        \n",
    "        else: \n",
    "            for value in values:\n",
    "                dot = {}\n",
    "                dot[first_key] = value\n",
    "                dots.append(dot)\n",
    "            return dots    \n",
    "    \n",
    "    def KFold(self, data, test_size, n_left = 4):\n",
    "        while n_left > 0:   \n",
    "            train, test = train_test_split(data, test_size=test_size, shuffle=True, stratify=data.Transported_True, random_state=self.random_state)\n",
    "            yield test\n",
    "            data = train\n",
    "            n_left -= 1\n",
    "        yield data\n",
    "        return\n",
    "         \n",
    "    def split_in_folds(self, n):\n",
    "        self.folds = []\n",
    "        generator = self.KFold(self.data, int(self.data.shape[0]*0.2), n-1)\n",
    "        for fold in range(n):\n",
    "            self.folds+= [next(generator)]\n",
    "        return True    \n",
    "        \n",
    "    \n",
    "    def run(self, return_output = False, verbose = 1, cv=5):\n",
    "        cv_results=[]\n",
    "        \n",
    "        self.split_in_folds(cv)\n",
    "        \n",
    "        param_grid = self.build_param_grid()\n",
    "        \n",
    "        for j, dot in enumerate(param_grid):\n",
    "            self.estimator.set_params(**{'base_estimator':tree})\n",
    "            self.estimator.set_params(**dot)\n",
    "            cv_scores = []\n",
    "            for r in range(cv):\n",
    "                test_fold = self.folds[r]\n",
    "                train_folds = self.folds[:r] + self.folds[r+1:]\n",
    "                train = pd.concat(train_folds, axis=0)\n",
    "                test_fold.reset_index(drop=True, inplace=True)\n",
    "                train.reset_index(drop=True, inplace=True)\n",
    "                self.estimator.fit(train.drop('Transported_True', axis=1), train.Transported_True)\n",
    "                preds = self.estimator.predict(test_fold.drop('Transported_True', axis=1))\n",
    "                accuracy = accuracy_score(test_fold.Transported_True, preds)\n",
    "                cv_scores+=[accuracy]\n",
    "\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(f'params: {j+1}/{len(param_grid)}, cv: {r+1}/{cv}, accuracy: {accuracy}')\n",
    "\n",
    "            avg_score = np.mean(cv_scores)\n",
    "            display.display(f'average score: {avg_score}')\n",
    "\n",
    "            cv_results += [(avg_score, j)]\n",
    "\n",
    "        cv_results.sort(key=lambda x: x[0], reverse=True)\n",
    "        self.best_score_ = cv_results[0][0]\n",
    "        self.best_bagging_params_ = param_grid[cv_results[0][1]]\n",
    "        self.cv_results = cv_results    \n",
    "        return\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'params: 5400/5400, cv: 5/5, accuracy: 0.7794371051120046'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'average score: 0.7684305740718831'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7763707351766012"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'base_estimator__max_depth': [ 7, 8, 9, 10],\n",
    "          'base_estimator__min_samples_leaf': [1, 5, 10, 15, 20, 30],\n",
    "          'base_estimator__max_leaf_nodes': [None, 10, 20, 50, 100],\n",
    "         'n_estimators':[4, 8, 10, 12, 15],\n",
    "          'max_samples':[0.7, 0.8, 0.9],\n",
    "          'max_features':[0.7, 0.8, 0.9]}\n",
    "v = Validation(train_prep, CustomBaggingClassifier(), params)\n",
    "v.run()\n",
    "v.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.9,\n",
       " 'max_samples': 0.9,\n",
       " 'n_estimators': 8,\n",
       " 'base_estimator__max_leaf_nodes': 50,\n",
       " 'base_estimator__min_samples_leaf': 30,\n",
       " 'base_estimator__max_depth': 10,\n",
       " 'base_estimator__criterion': 'entropy',\n",
       " 'base_estimator__class_weight': 'balanced'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.best_bagging_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7952412368787268,\n",
       " BaggingClassifier(estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                    criterion='entropy',\n",
       "                                                    max_depth=10,\n",
       "                                                    max_leaf_nodes=100,\n",
       "                                                    min_samples_leaf=20),\n",
       "                   max_features=0.8, max_samples=0.9, n_estimators=12,\n",
       "                   random_state=42))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "params = {'estimator__class_weight':['balanced'], \n",
    "          'estimator__criterion':['entropy'],\n",
    "          'estimator__max_depth': [ 7, 8, 9, 10],\n",
    "          'estimator__min_samples_leaf': [1, 5, 10, 15, 20, 30],\n",
    "          'estimator__max_leaf_nodes': [None, 10, 20, 50, 100],\n",
    "         'n_estimators':[4, 8, 10, 12, 15],\n",
    "          'max_samples':[0.7, 0.8, 0.9],\n",
    "          'max_features':[ 0.8, 0.9]}\n",
    "train_X.reset_index(inplace=True, drop=True)\n",
    "train_y.reset_index(inplace=True, drop=True)\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(), random_state=42)\n",
    "grid = GridSearchCV(bagging, params, scoring='accuracy', verbose=1)\n",
    "grid.fit(train_X, train_y)\n",
    "grid.best_score_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6750 candidates, totalling 33750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "11250 fits failed out of a total of 33750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "11250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2', 'auto' (deprecated)} or None. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.77303961 0.782817   0.78293134 ... 0.78350738 0.78707311 0.78626778]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7996117631722265,\n",
       " RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                        max_depth=15, max_samples=0.9, min_samples_leaf=10,\n",
       "                        n_estimators=15, random_state=42))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'class_weight':['balanced'], \n",
    "          'criterion':['entropy'],\n",
    "          'max_depth': [ 7, 8, 9, 10, 15],\n",
    "          'min_samples_leaf': [1, 5, 10, 15, 20, 30],\n",
    "          'max_leaf_nodes': [None, 10, 20, 50, 100],\n",
    "         'n_estimators':[4, 8, 10, 12, 15],\n",
    "          'max_samples':[0.7, 0.8, 0.9],\n",
    "          'max_features':['sqrt', 'log', None]}\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "grid = GridSearchCV(forest_clf, params, scoring='accuracy', verbose=1)\n",
    "grid.fit(train_X, train_y)\n",
    "grid.best_score_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bagging homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
