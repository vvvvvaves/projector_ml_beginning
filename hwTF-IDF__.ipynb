{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2112f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from textblob import Word, TextBlob\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063ce9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96489054",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups()\n",
    "test = fetch_20newsgroups(subset=\"test\")\n",
    "X_train, y_train = train['data'], train['target']\n",
    "X_test, y_test = test['data'], test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561fbe3b",
   "metadata": {},
   "source": [
    "## Preprocessing and regex features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44ef624",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = lambda text: ''.join(filter(lambda x: x.isalpha() or x in [' ', '\\n', '.', ',', ':', ',', '!', '?'] or x.isdigit(), text))\n",
    "get_sentences = lambda text: re.findall(r'[A-Z][^\\.]*[\\.|\\?|\\!][$|\\s]', text)\n",
    "get_weird_sentences = lambda text: re.findall(r'[\\s|^|\\.][A-Z][^\\.]*[\\.|\\?|\\!]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c30748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbfd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_specific(data, topics):\n",
    "    split_txts = []\n",
    "    for txt in data:\n",
    "        split_txt = {}\n",
    "        for topic in topics:\n",
    "            \n",
    "            if topic+':' not in txt:\n",
    "                split_txt[topic] = ''\n",
    "            else:\n",
    "                s = txt.split(topic + ':')[1]\n",
    "                next_topic = re.findall('[a-z\\-A-Z]+:',s)\n",
    "                if next_topic:\n",
    "#                     s = s.split(re.findall('[a-z\\-A-Z]+:',s)[0])[0]\n",
    "                    s = s.split(re.findall('[a-z\\-A-Z]+:|$',s)[0])[0]\n",
    "                split_txt[topic] = s\n",
    "                txt = txt.replace(s, ' ').replace(topic+':', ' ')         \n",
    "        split_txt['the_rest'] = txt\n",
    "        split_txts += [split_txt]\n",
    "        \n",
    "    return split_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac4bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_only = lambda txt: ''.join(filter(lambda c: c.isalpha(), txt)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afcb723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_words = lambda text: len(re.findall('[A-Z]{2,}', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ad9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train, columns=['text'])\n",
    "df['text'] = df['text'].apply(clean_sentences)\n",
    "df['question_marks_cnt'] = df['text'].str.count('\\?')\n",
    "df['exclamation_marks_cnt'] = df['text'].str.count('\\!')\n",
    "df['uppercase_words_count'] = df['text'].apply(uppercase_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5c0d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "df_ = pd.DataFrame(split_specific(df['text'], ['From']))\n",
    "df_['From'] = df_['From'].apply(lambda f: ' '.join(f.strip().split(' ')[0].split('.')))\n",
    "df_['sentences'] = df_.the_rest.apply(get_sentences)\n",
    "df_['sentences_count'] = df_['sentences'].apply(len)\n",
    "df_.loc[df_.sentences_count == 0, 'the_rest'] = df_.loc[df_.sentences_count == 0, 'the_rest'].apply(get_weird_sentences)\n",
    "df_['sentences_count'] = df_['sentences'].apply(len)\n",
    "df_.loc[df_.sentences_count == 0, 'sentences'] = [['']]*df_.loc[df_.sentences_count == 0, 'sentences'].shape[0]\n",
    "df_['median_sentence_len'] = df_['sentences'].apply(lambda arr: np.median(np.array([len(item) for item in arr]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84971a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['polarity_1_sntc'] = df_['sentences'].apply(lambda s: TextBlob(s[0]).sentiment.polarity if len(s) > 0 else np.nan)\n",
    "df_['subjectivity_1_sntc'] = df_['sentences'].apply(lambda s: TextBlob(s[0]).sentiment.subjectivity  if len(s) > 0 else np.nan)\n",
    "df_['polarity_last_sntc'] = df_['sentences'].apply(lambda s: TextBlob(s[-1]).sentiment.polarity  if len(s) > 0 else np.nan)\n",
    "df_['subjectivity_last_sntc'] = df_['sentences'].apply(lambda s: TextBlob(s[-1]).sentiment.subjectivity  if len(s) > 0 else np.nan)\n",
    "df_.drop(['sentences', 'the_rest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e5aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71ab239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question_marks_cnt</th>\n",
       "      <th>exclamation_marks_cnt</th>\n",
       "      <th>uppercase_words_count</th>\n",
       "      <th>From</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>median_sentence_len</th>\n",
       "      <th>polarity_1_sntc</th>\n",
       "      <th>subjectivity_1_sntc</th>\n",
       "      <th>polarity_last_sntc</th>\n",
       "      <th>subjectivity_last_sntc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxstwam.umd.edu wheres my thing\\nSubje...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>lerxstwam umd edu</td>\n",
       "      <td>8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuocarson.u.washington.edu Guy Kuo\\nS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>guykuocarson u washington edu</td>\n",
       "      <td>4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  question_marks_cnt  \\\n",
       "0  From: lerxstwam.umd.edu wheres my thing\\nSubje...                   1   \n",
       "1  From: guykuocarson.u.washington.edu Guy Kuo\\nS...                   0   \n",
       "\n",
       "   exclamation_marks_cnt  uppercase_words_count  \\\n",
       "0                      1                      2   \n",
       "1                      0                      7   \n",
       "\n",
       "                            From  sentences_count  median_sentence_len  \\\n",
       "0              lerxstwam umd edu                8                 49.0   \n",
       "1  guykuocarson u washington edu                4                 94.0   \n",
       "\n",
       "   polarity_1_sntc  subjectivity_1_sntc  polarity_last_sntc  \\\n",
       "0        -0.208333             0.333333                 0.0   \n",
       "1         0.750000             0.950000                 0.2   \n",
       "\n",
       "   subjectivity_last_sntc  \n",
       "0                     0.0  \n",
       "1                     0.2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7d0581",
   "metadata": {},
   "source": [
    "## CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31be1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "                    analyzer='word', #{‘word’, ‘char’, ‘char_wb’} \n",
    "                    ngram_range=(1,2),\n",
    "                    stop_words='english',\n",
    "                    vocabulary=None,\n",
    "                    max_df=0.4, #0.4\n",
    "                    min_df=30, #30\n",
    "#                     max_features=6,\n",
    "                    preprocessor=remove_digits\n",
    "                    )\n",
    "words = vectorizer.fit_transform(df['text'])\n",
    "words = pd.DataFrame(words.astype(np.byte).todense(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074825a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able use</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>za</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoology kipling</th>\n",
       "      <th>zoology lines</th>\n",
       "      <th>zx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 7460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaron  ab  abandoned  abc  ability  able  able use  abortion  ...  \\\n",
       "0   0    0      0   0          0    0        0     0         0         0  ...   \n",
       "1   0    0      0   0          0    0        0     0         0         0  ...   \n",
       "\n",
       "   za  zealand  zero  zeus  zip  zone  zoology  zoology kipling  \\\n",
       "0   0        0     0     0    0     0        0                0   \n",
       "1   0        0     0     0    0     0        0                0   \n",
       "\n",
       "   zoology lines  zx  \n",
       "0              0   0  \n",
       "1              0   0  \n",
       "\n",
       "[2 rows x 7460 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90c0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "                    analyzer='char_wb', #{‘word’, ‘char’, ‘char_wb’} \n",
    "                    ngram_range=(4,9),\n",
    "                    vocabulary=None,\n",
    "                    max_df=400,\n",
    "                    min_df=200,\n",
    "                    lowercase=True,\n",
    "#                     max_features=6,\n",
    "                    preprocessor=letters_only\n",
    "                    )\n",
    "chars = vectorizer.fit_transform(df['text'])\n",
    "chars = pd.DataFrame(chars.astype(np.byte).todense(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1c8213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frome</th>\n",
       "      <th>fromf</th>\n",
       "      <th>froml</th>\n",
       "      <th>fromma</th>\n",
       "      <th>fromn</th>\n",
       "      <th>fromw</th>\n",
       "      <th>sub</th>\n",
       "      <th>subj</th>\n",
       "      <th>subje</th>\n",
       "      <th>subjec</th>\n",
       "      <th>...</th>\n",
       "      <th>zationin</th>\n",
       "      <th>zationl</th>\n",
       "      <th>zationne</th>\n",
       "      <th>zationo</th>\n",
       "      <th>zationr</th>\n",
       "      <th>zationst</th>\n",
       "      <th>zationw</th>\n",
       "      <th>zens</th>\n",
       "      <th>zethe</th>\n",
       "      <th>zine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 18600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    frome   fromf   froml   fromma   fromn   fromw   sub   subj   subje  \\\n",
       "0       0       0       1        0       0       0     0      0       0   \n",
       "1       0       0       0        0       0       0     0      0       0   \n",
       "\n",
       "    subjec  ...  zationin  zationl  zationne  zationo  zationr  zationst  \\\n",
       "0        0  ...         0        0         0        0        0         0   \n",
       "1        0  ...         0        0         0        0        0         0   \n",
       "\n",
       "   zationw  zens  zethe  zine  \n",
       "0        0     0      0     0  \n",
       "1        0     0      0     0  \n",
       "\n",
       "[2 rows x 18600 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30490575",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([words, chars, df.drop(['text', 'From'], axis=1)], axis=1)\n",
    "final.drop(final.columns[final.columns.duplicated()], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1341f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able use</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>zine</th>\n",
       "      <th>question_marks_cnt</th>\n",
       "      <th>exclamation_marks_cnt</th>\n",
       "      <th>uppercase_words_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>median_sentence_len</th>\n",
       "      <th>polarity_1_sntc</th>\n",
       "      <th>subjectivity_1_sntc</th>\n",
       "      <th>polarity_last_sntc</th>\n",
       "      <th>subjectivity_last_sntc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaron  ab  abandoned  abc  ability  able  able use  abortion  ...  \\\n",
       "0   0    0      0   0          0    0        0     0         0         0  ...   \n",
       "1   0    0      0   0          0    0        0     0         0         0  ...   \n",
       "\n",
       "   zine  question_marks_cnt  exclamation_marks_cnt  uppercase_words_count  \\\n",
       "0     0                   1                      1                      2   \n",
       "1     0                   0                      0                      7   \n",
       "\n",
       "   sentences_count  median_sentence_len  polarity_1_sntc  subjectivity_1_sntc  \\\n",
       "0                8                 49.0        -0.208333             0.333333   \n",
       "1                4                 94.0         0.750000             0.950000   \n",
       "\n",
       "   polarity_last_sntc  subjectivity_last_sntc  \n",
       "0                 0.0                     0.0  \n",
       "1                 0.2                     0.2  \n",
       "\n",
       "[2 rows x 24599 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74df99e",
   "metadata": {},
   "source": [
    "**Leaving out only the most important features. It greatly improves score on Logistic Regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c25255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "final_ = imputer.fit_transform(final)\n",
    "final_ = StandardScaler().fit_transform(final_)\n",
    "final_ = pd.DataFrame(final_, columns=final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f420ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(penalty='l1',\n",
    "                         C=0.1,\n",
    "                         multi_class='ovr', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42,\n",
    "                         solver='liblinear')\n",
    "logistic_reg_results = cross_validate(reg, final_, y_train, cv=fixed_skf, scoring='accuracy',verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(final_, y_train)\n",
    "weights = list(zip(np.abs(reg.coef_).sum(axis=0), final_.columns))\n",
    "weights.sort(key = lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [x[1] for x in weights[:5_000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c49e3",
   "metadata": {},
   "source": [
    "**LightGBM with all of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a986c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tcv_agg's train multi_error: 0.141506 + 0.00191815\tcv_agg's valid multi_error: 0.238731 + 0.0052255\n",
      "[20]\tcv_agg's train multi_error: 0.0689411 + 0.00122781\tcv_agg's valid multi_error: 0.202051 + 0.00492652\n",
      "[30]\tcv_agg's train multi_error: 0.0299188 + 0.0016269\tcv_agg's valid multi_error: 0.177745 + 0.00761353\n",
      "[40]\tcv_agg's train multi_error: 0.0117554 + 0.00159633\tcv_agg's valid multi_error: 0.161659 + 0.00641955\n",
      "[50]\tcv_agg's train multi_error: 0.00256322 + 0.000488285\tcv_agg's valid multi_error: 0.151494 + 0.00627843\n",
      "[60]\tcv_agg's train multi_error: 0.000574519 + 0.000165395\tcv_agg's valid multi_error: 0.147694 + 0.00767489\n",
      "[70]\tcv_agg's train multi_error: 0.000132579 + 8.28635e-09\tcv_agg's valid multi_error: 0.142833 + 0.007058\n",
      "[80]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.140358 + 0.00722785\n",
      "[90]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.139032 + 0.00619996\n",
      "[100]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.136469 + 0.00577867\n",
      "[110]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.134701 + 0.00633649\n",
      "[120]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.132668 + 0.00483274\n",
      "[130]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.132314 + 0.00448684\n",
      "[140]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.1309 + 0.00592636\n",
      "[150]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.130193 + 0.0070719\n",
      "[160]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.12984 + 0.00678106\n",
      "[170]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.129044 + 0.00742558\n",
      "[180]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.127984 + 0.00662622\n",
      "[190]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.126923 + 0.00629309\n",
      "[200]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.125509 + 0.00600737\n",
      "[210]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.12489 + 0.00585879\n",
      "[220]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.124625 + 0.00633709\n",
      "[230]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.124006 + 0.00701377\n",
      "[240]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.122946 + 0.00728964\n",
      "[250]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.12436 + 0.00738403\n",
      "Early stopping, best iteration is:\n",
      "[240]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.122946 + 0.00728964\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    #default\n",
    "    \"objective\": \"multiclass\",\n",
    "    'num_classes': 20, \n",
    "    \"learning_rate\": 0.07,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"seed\": 42,\n",
    "    \"num_threads\":4,\n",
    "    \n",
    "# #     #regularization\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"subsample\": 0.7, \n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "#     \"num_leaves\":100,\n",
    "    \"verbose\":-1\n",
    "}\n",
    "lgb_train = lgb.Dataset(final, label=y_train, free_raw_data=False)\n",
    "lgb_result = lgb.cv(lgb_params, lgb_train, 10_000, folds=fixed_skf, callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)], eval_train_metric=True, return_cvbooster=True)\n",
    "lgb_params['n_estimators'] = lgb_result[\"cvbooster\"].best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72359a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test: 0.877054\n",
      "accuracy on train: 0.999911612\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on test: ' + str(1-0.122946))\n",
    "print('accuracy on train: ' + str(1-8.8388e-05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5356124",
   "metadata": {},
   "source": [
    "**LightGBM with 5000 most important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76f56233",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tcv_agg's train multi_error: 0.152731 + 0.0020129\tcv_agg's valid multi_error: 0.251017 + 0.00197581\n",
      "[20]\tcv_agg's train multi_error: 0.0813593 + 0.000794545\tcv_agg's valid multi_error: 0.203819 + 0.00760376\n",
      "[30]\tcv_agg's train multi_error: 0.039597 + 0.00098422\tcv_agg's valid multi_error: 0.182253 + 0.00566177\n",
      "[40]\tcv_agg's train multi_error: 0.0161305 + 0.00102973\tcv_agg's valid multi_error: 0.163338 + 0.00596816\n",
      "[50]\tcv_agg's train multi_error: 0.00565671 + 0.000380176\tcv_agg's valid multi_error: 0.154676 + 0.00706001\n",
      "[60]\tcv_agg's train multi_error: 0.00150258 + 0.000250099\tcv_agg's valid multi_error: 0.147075 + 0.00490728\n",
      "[70]\tcv_agg's train multi_error: 0.00035354 + 6.24791e-05\tcv_agg's valid multi_error: 0.140888 + 0.00689844\n",
      "[80]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.139916 + 0.00602862\n",
      "[90]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.137441 + 0.00857689\n",
      "[100]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.133464 + 0.00932713\n",
      "[110]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.131784 + 0.00791117\n",
      "[120]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.129751 + 0.0086274\n",
      "[130]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.130724 + 0.00901936\n",
      "[140]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.129309 + 0.00719673\n",
      "[150]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.127453 + 0.00758904\n",
      "[160]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.126481 + 0.00678797\n",
      "[170]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.126127 + 0.00775804\n",
      "[180]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.126923 + 0.00794616\n",
      "Early stopping, best iteration is:\n",
      "[172]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.125685 + 0.007508\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    #default\n",
    "    \"objective\": \"multiclass\",\n",
    "    'num_classes': 20, \n",
    "    \"learning_rate\": 0.07,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"seed\": 42,\n",
    "    \"num_threads\":4,\n",
    "    \n",
    "# #     #regularization\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"subsample\": 0.7, \n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "#     \"num_leaves\":100,\n",
    "    \"verbose\":-1\n",
    "}\n",
    "lgb_train = lgb.Dataset(final[selected_columns], label=y_train, free_raw_data=False)\n",
    "lgb_result = lgb.cv(lgb_params, lgb_train, 10_000, folds=fixed_skf, callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)], eval_train_metric=True, return_cvbooster=True)\n",
    "lgb_params['n_estimators'] = lgb_result[\"cvbooster\"].best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b385f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train multi_error-mean    0.999912\n",
       "valid multi_error-mean    0.874315\n",
       "Name: 171, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgb_result = pd.DataFrame()\n",
    "df_lgb_result['train multi_error-mean'] = lgb_result['train multi_error-mean']\n",
    "df_lgb_result['valid multi_error-mean'] = lgb_result['valid multi_error-mean']\n",
    "1-df_lgb_result.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61893f6",
   "metadata": {},
   "source": [
    "**Logistic Regression with all of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7154d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(penalty='l2',\n",
    "                         C=0.01, #0.01 ---> 0.7966224069213816\n",
    "                         multi_class='multinomial', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42)\n",
    "logistic_reg_results_full = cross_validate(reg, final_, y_train, cv=fixed_skf, scoring='accuracy',verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe1c2621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       66.131167\n",
       "score_time      0.284277\n",
       "test_score      0.841435\n",
       "train_score     0.999867\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logistic_reg_results_full).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ba89c",
   "metadata": {},
   "source": [
    "**Logistic Regression with 5000 most important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18656745",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(penalty='l2',\n",
    "                         C=0.01, #0.01 ---> 0.7966224069213816\n",
    "                         multi_class='multinomial', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42)\n",
    "logistic_reg_results = cross_validate(reg, final_[selected_columns], y_train, cv=fixed_skf, scoring='accuracy',verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e89475c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       11.329509\n",
       "score_time      0.051689\n",
       "test_score      0.882092\n",
       "train_score     0.999779\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logistic_reg_results).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd5e71",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4597dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "                    analyzer='word',\n",
    "                    ngram_range=(1,2),\n",
    "                    stop_words='english',\n",
    "                    vocabulary=None,\n",
    "                    max_df=0.4, #0.8 \n",
    "                    min_df = 30, #50\n",
    "                    max_features=None,\n",
    "                    smooth_idf=False,\n",
    "                    norm='l2',\n",
    "                    preprocessor=remove_digits)\n",
    "bag = vectorizer.fit_transform(df['text'])\n",
    "words = pd.DataFrame(bag.astype(np.float32).todense(), columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fe5bf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able use</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>za</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoology kipling</th>\n",
       "      <th>zoology lines</th>\n",
       "      <th>zx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 7460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaron   ab  abandoned  abc  ability  able  able use  abortion  \\\n",
       "0  0.0  0.0    0.0  0.0        0.0  0.0      0.0   0.0       0.0       0.0   \n",
       "1  0.0  0.0    0.0  0.0        0.0  0.0      0.0   0.0       0.0       0.0   \n",
       "\n",
       "   ...   za  zealand  zero  zeus  zip  zone  zoology  zoology kipling  \\\n",
       "0  ...  0.0      0.0   0.0   0.0  0.0   0.0      0.0              0.0   \n",
       "1  ...  0.0      0.0   0.0   0.0  0.0   0.0      0.0              0.0   \n",
       "\n",
       "   zoology lines   zx  \n",
       "0            0.0  0.0  \n",
       "1            0.0  0.0  \n",
       "\n",
       "[2 rows x 7460 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a681b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "                    analyzer='char_wb',\n",
    "                    ngram_range=(4,9),\n",
    "                    vocabulary=None,\n",
    "                    max_df=400, #0.8 \n",
    "                    min_df = 200, #50\n",
    "                    max_features=None,\n",
    "                    smooth_idf=False,\n",
    "                    norm='l2',\n",
    "                    preprocessor=letters_only)\n",
    "bag = vectorizer.fit_transform(df['text'])\n",
    "chars = pd.DataFrame(bag.astype(np.float32).todense(), columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3dd66e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frome</th>\n",
       "      <th>fromf</th>\n",
       "      <th>froml</th>\n",
       "      <th>fromma</th>\n",
       "      <th>fromn</th>\n",
       "      <th>fromw</th>\n",
       "      <th>sub</th>\n",
       "      <th>subj</th>\n",
       "      <th>subje</th>\n",
       "      <th>subjec</th>\n",
       "      <th>...</th>\n",
       "      <th>zationin</th>\n",
       "      <th>zationl</th>\n",
       "      <th>zationne</th>\n",
       "      <th>zationo</th>\n",
       "      <th>zationr</th>\n",
       "      <th>zationst</th>\n",
       "      <th>zationw</th>\n",
       "      <th>zens</th>\n",
       "      <th>zethe</th>\n",
       "      <th>zine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 18600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    frome   fromf     froml   fromma   fromn   fromw   sub   subj   subje  \\\n",
       "0     0.0     0.0  0.059901      0.0     0.0     0.0   0.0    0.0     0.0   \n",
       "1     0.0     0.0  0.000000      0.0     0.0     0.0   0.0    0.0     0.0   \n",
       "\n",
       "    subjec  ...  zationin  zationl  zationne  zationo  zationr  zationst  \\\n",
       "0      0.0  ...       0.0      0.0       0.0      0.0      0.0       0.0   \n",
       "1      0.0  ...       0.0      0.0       0.0      0.0      0.0       0.0   \n",
       "\n",
       "   zationw  zens  zethe  zine  \n",
       "0      0.0   0.0    0.0   0.0  \n",
       "1      0.0   0.0    0.0   0.0  \n",
       "\n",
       "[2 rows x 18600 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46019f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([words, chars, df.drop(['text', 'From'], axis=1)], axis=1)\n",
    "final.drop(final.columns[final.columns.duplicated()], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1e81c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "final_ = imputer.fit_transform(final)\n",
    "final_ = StandardScaler().fit_transform(final_)\n",
    "final_ = pd.DataFrame(final_, columns=final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "121c74d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able use</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>zine</th>\n",
       "      <th>question_marks_cnt</th>\n",
       "      <th>exclamation_marks_cnt</th>\n",
       "      <th>uppercase_words_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>median_sentence_len</th>\n",
       "      <th>polarity_1_sntc</th>\n",
       "      <th>subjectivity_1_sntc</th>\n",
       "      <th>polarity_last_sntc</th>\n",
       "      <th>subjectivity_last_sntc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0613</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>-0.071476</td>\n",
       "      <td>-0.078557</td>\n",
       "      <td>-0.041258</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.114927</td>\n",
       "      <td>-0.239743</td>\n",
       "      <td>-0.050097</td>\n",
       "      <td>-0.052426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120898</td>\n",
       "      <td>-0.093352</td>\n",
       "      <td>-0.046756</td>\n",
       "      <td>-0.086356</td>\n",
       "      <td>-0.184711</td>\n",
       "      <td>-0.649253</td>\n",
       "      <td>-0.931508</td>\n",
       "      <td>0.160459</td>\n",
       "      <td>-0.281963</td>\n",
       "      <td>-0.875187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0613</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>-0.071476</td>\n",
       "      <td>-0.078557</td>\n",
       "      <td>-0.041258</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.114927</td>\n",
       "      <td>-0.239743</td>\n",
       "      <td>-0.050097</td>\n",
       "      <td>-0.052426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120898</td>\n",
       "      <td>-0.136909</td>\n",
       "      <td>-0.086395</td>\n",
       "      <td>-0.057868</td>\n",
       "      <td>-0.331613</td>\n",
       "      <td>0.085328</td>\n",
       "      <td>3.922110</td>\n",
       "      <td>2.855572</td>\n",
       "      <td>0.561385</td>\n",
       "      <td>-0.216227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa       aaa     aaron        ab  abandoned       abc   ability  \\\n",
       "0 -0.0613 -0.051056 -0.071476 -0.078557  -0.041258 -0.050063 -0.114927   \n",
       "1 -0.0613 -0.051056 -0.071476 -0.078557  -0.041258 -0.050063 -0.114927   \n",
       "\n",
       "       able  able use  abortion  ...      zine  question_marks_cnt  \\\n",
       "0 -0.239743 -0.050097 -0.052426  ... -0.120898           -0.093352   \n",
       "1 -0.239743 -0.050097 -0.052426  ... -0.120898           -0.136909   \n",
       "\n",
       "   exclamation_marks_cnt  uppercase_words_count  sentences_count  \\\n",
       "0              -0.046756              -0.086356        -0.184711   \n",
       "1              -0.086395              -0.057868        -0.331613   \n",
       "\n",
       "   median_sentence_len  polarity_1_sntc  subjectivity_1_sntc  \\\n",
       "0            -0.649253        -0.931508             0.160459   \n",
       "1             0.085328         3.922110             2.855572   \n",
       "\n",
       "   polarity_last_sntc  subjectivity_last_sntc  \n",
       "0           -0.281963               -0.875187  \n",
       "1            0.561385               -0.216227  \n",
       "\n",
       "[2 rows x 24599 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88efc11",
   "metadata": {},
   "source": [
    "**Selecting features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1b788ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(penalty='l1',\n",
    "                         C=0.1,\n",
    "                         multi_class='ovr', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42,\n",
    "                         solver='liblinear')\n",
    "logistic_reg_results = cross_validate(reg, final_, y_train, cv=fixed_skf, scoring='accuracy',verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "25f383b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(penalty='l1',\n",
    "                         C=0.1,\n",
    "                         multi_class='ovr', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42,\n",
    "                         solver='liblinear')\n",
    "reg.fit(final_, y_train)\n",
    "weights = list(zip(np.abs(reg.coef_).sum(axis=0), final_.columns))\n",
    "weights.sort(key = lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af937acd",
   "metadata": {},
   "source": [
    "**Logistic Regression with all of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "73e1e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=1.000, test=0.882) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=1.000, test=0.875) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=1.000, test=0.876) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(penalty='l2',\n",
    "                         C=0.01, #0.01 ---> 0.7966224069213816\n",
    "                         multi_class='multinomial', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42)\n",
    "logistic_reg_results_tfidf = cross_validate(reg, final_, y_train, cv=fixed_skf, scoring='accuracy',verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b111927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       67.260816\n",
       "score_time      0.308254\n",
       "test_score      0.877850\n",
       "train_score     0.999867\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logistic_reg_results_tfidf).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d977fd99",
   "metadata": {},
   "source": [
    "**Logistic Regression with 5000 most important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2c4babda",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [x[1] for x in weights[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc10719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=1.000, test=0.931) total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=1.000, test=0.934) total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   18.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=1.000, test=0.926) total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   29.4s finished\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(penalty='l2',\n",
    "                         C=0.01,\n",
    "                         multi_class='multinomial', #multinomial, ovr\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=4,\n",
    "                         random_state=42)\n",
    "logistic_reg_results_tfidf = cross_validate(reg, final_[selected_columns], y_train, cv=fixed_skf, scoring='accuracy',verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "590bf8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       9.636649\n",
       "score_time     0.055589\n",
       "test_score     0.930440\n",
       "train_score    0.999779\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logistic_reg_results_tfidf).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a854e",
   "metadata": {},
   "source": [
    "**LightGBM with all of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c93a5715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tcv_agg's train multi_error: 0.113179 + 0.00267901\tcv_agg's valid multi_error: 0.23882 + 0.00654345\n",
      "[20]\tcv_agg's train multi_error: 0.0514408 + 0.00114882\tcv_agg's valid multi_error: 0.207796 + 0.00706486\n",
      "[30]\tcv_agg's train multi_error: 0.0197986 + 0.00165478\tcv_agg's valid multi_error: 0.187379 + 0.00799176\n",
      "[40]\tcv_agg's train multi_error: 0.00654061 + 0.000982491\tcv_agg's valid multi_error: 0.174917 + 0.00773413\n",
      "[50]\tcv_agg's train multi_error: 0.00154676 + 0.000250036\tcv_agg's valid multi_error: 0.165283 + 0.00860688\n",
      "[60]\tcv_agg's train multi_error: 0.000220967 + 6.25039e-05\tcv_agg's valid multi_error: 0.158477 + 0.00785107\n",
      "[70]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.152909 + 0.00770467\n",
      "[80]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.149196 + 0.00797545\n",
      "[90]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.146015 + 0.00868665\n",
      "[100]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.143982 + 0.00944339\n",
      "[110]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.143098 + 0.00949167\n",
      "[120]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.14027 + 0.00900168\n",
      "[130]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.138856 + 0.00955336\n",
      "[140]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.13753 + 0.00857783\n",
      "[150]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.137264 + 0.00845883\n",
      "[160]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.136646 + 0.00837856\n",
      "[170]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.135232 + 0.00911528\n",
      "[180]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.133817 + 0.00879362\n",
      "[190]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.133376 + 0.00861776\n",
      "[200]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.13258 + 0.00866679\n",
      "[210]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.132403 + 0.00924133\n",
      "[220]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.131696 + 0.00889118\n",
      "[230]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.129928 + 0.00889783\n",
      "[240]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.130282 + 0.00910769\n",
      "Early stopping, best iteration is:\n",
      "[235]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.12984 + 0.00899871\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    #default\n",
    "    \"objective\": \"multiclass\",\n",
    "    'num_classes': 20, \n",
    "    \"learning_rate\": 0.06,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"seed\": 42,\n",
    "    \"num_threads\":4,\n",
    "    \n",
    "# #     #regularization\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"subsample\": 0.8, \n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 45,\n",
    "#     \"num_leaves\":100,\n",
    "    \"verbose\":-1\n",
    "}\n",
    "lgb_train = lgb.Dataset(final, label=y_train, free_raw_data=False)\n",
    "lgb_result = lgb.cv(lgb_params, lgb_train, 10_000, folds=fixed_skf, callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)], eval_train_metric=True, return_cvbooster=True)\n",
    "lgb_params['n_estimators'] = lgb_result[\"cvbooster\"].best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be64fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test: 0.87016\n",
      "accuracy on train: 0.999911612\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on test: ' + str(1-0.12984))\n",
    "print('accuracy on train: ' + str(1-8.8388e-05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a44d43",
   "metadata": {},
   "source": [
    "**LightGBM with 5000 most important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91e2a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tcv_agg's train multi_error: 0.137175 + 0.00281209\tcv_agg's valid multi_error: 0.241737 + 0.0117046\n",
      "[20]\tcv_agg's train multi_error: 0.0673061 + 0.00100991\tcv_agg's valid multi_error: 0.20709 + 0.00943918\n",
      "[30]\tcv_agg's train multi_error: 0.0301397 + 0.00157894\tcv_agg's valid multi_error: 0.184728 + 0.0081641\n",
      "[40]\tcv_agg's train multi_error: 0.0105622 + 0.00133616\tcv_agg's valid multi_error: 0.170232 + 0.00746583\n",
      "[50]\tcv_agg's train multi_error: 0.00318189 + 0.000572722\tcv_agg's valid multi_error: 0.15777 + 0.00640606\n",
      "[60]\tcv_agg's train multi_error: 0.000353546 + 6.25081e-05\tcv_agg's valid multi_error: 0.150699 + 0.00611481\n",
      "[70]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.145396 + 0.00645257\n",
      "[80]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.142302 + 0.00571751\n",
      "[90]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.139385 + 0.00536236\n",
      "[100]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.135673 + 0.00549584\n",
      "[110]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.132933 + 0.00543209\n",
      "[120]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.131519 + 0.00518855\n",
      "[130]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.13037 + 0.00580926\n",
      "[140]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.129309 + 0.0058649\n",
      "[150]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.126481 + 0.00575354\n",
      "[160]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.125597 + 0.00566387\n",
      "Early stopping, best iteration is:\n",
      "[156]\tcv_agg's train multi_error: 8.8388e-05 + 6.24998e-05\tcv_agg's valid multi_error: 0.12436 + 0.00522223\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    #default\n",
    "    \"objective\": \"multiclass\",\n",
    "    'num_classes': 20, \n",
    "    \"learning_rate\": 0.06,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"multi_error\",\n",
    "    \"seed\": 42,\n",
    "    \"num_threads\":4,\n",
    "    \n",
    "# #     #regularization\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"subsample\": 0.8, \n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 45,\n",
    "#     \"num_leaves\":100,\n",
    "    \"verbose\":-1\n",
    "}\n",
    "lgb_train = lgb.Dataset(final[selected_columns], label=y_train, free_raw_data=False)\n",
    "lgb_result = lgb.cv(lgb_params, lgb_train, 10_000, folds=fixed_skf, callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)], eval_train_metric=True, return_cvbooster=True)\n",
    "lgb_params['n_estimators'] = lgb_result[\"cvbooster\"].best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ba99b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train multi_error-mean    0.999912\n",
       "valid multi_error-mean    0.875640\n",
       "Name: 155, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgb_result = pd.DataFrame()\n",
    "df_lgb_result['train multi_error-mean'] = lgb_result['train multi_error-mean']\n",
    "df_lgb_result['valid multi_error-mean'] = lgb_result['valid multi_error-mean']\n",
    "1-df_lgb_result.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2256785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_to_look_at_table = []\n",
    "easy_to_look_at_table+=[{'name':'TF-IDF, LightGBM, 25000 features', 'test': 0.87016, 'train': 0.999911612, 'cv_time': 'too much'}]\n",
    "easy_to_look_at_table+=[{'name':'TF-IDF, LightGBM, 5000 features', 'test': 0.875640, 'train': 0.999912, 'cv_time': 'less than 3 minutes'}]\n",
    "\n",
    "easy_to_look_at_table+=[{'name':'TF-IDF, LogisticRegression, 5000 features', 'test': 0.930440, 'train': 0.999912, 'cv_time': 9.636649+0.055589}]\n",
    "easy_to_look_at_table+=[{'name':'TF-IDF, LogisticRegression, 25000 features', 'train': 0.999867, 'test': 0.877850, 'cv_time':  67.260816+ 0.308254}]\n",
    "\n",
    "easy_to_look_at_table+=[{'name':'CountVectorizer, LogisticRegression, 5000 features', 'train': 0.999779, 'test': 0.882092, 'cv_time':  11.329509+ 0.05}]\n",
    "easy_to_look_at_table+=[{'name':'CountVectorizer, LogisticRegression, 25000 features', 'train': 0.999867, 'test': 0.841435, 'cv_time':  66.131167+ 0.284277}]\n",
    "\n",
    "easy_to_look_at_table+=[{'name':'CountVectorizer, LightGBM, 5000 features', 'train': 0.999912, 'test': 0.874315, 'cv_time':  'less than 3 minutes'}]\n",
    "easy_to_look_at_table+=[{'name':'CountVectorizer, LightGBM, 25000 features', 'train': 0.999911612, 'test': 0.877054, 'cv_time':  'too much'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d71951a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>cv_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CountVectorizer, LogisticRegression, 25000 fea...</td>\n",
       "      <td>0.841435</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>66.415444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF, LightGBM, 25000 features</td>\n",
       "      <td>0.870160</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>too much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CountVectorizer, LightGBM, 5000 features</td>\n",
       "      <td>0.874315</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>less than 3 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF, LightGBM, 5000 features</td>\n",
       "      <td>0.875640</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>less than 3 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CountVectorizer, LightGBM, 25000 features</td>\n",
       "      <td>0.877054</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>too much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF, LogisticRegression, 25000 features</td>\n",
       "      <td>0.877850</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>67.56907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CountVectorizer, LogisticRegression, 5000 feat...</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>11.379509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF, LogisticRegression, 5000 features</td>\n",
       "      <td>0.930440</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>9.692238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name      test     train  \\\n",
       "5  CountVectorizer, LogisticRegression, 25000 fea...  0.841435  0.999867   \n",
       "0                   TF-IDF, LightGBM, 25000 features  0.870160  0.999912   \n",
       "6           CountVectorizer, LightGBM, 5000 features  0.874315  0.999912   \n",
       "1                    TF-IDF, LightGBM, 5000 features  0.875640  0.999912   \n",
       "7          CountVectorizer, LightGBM, 25000 features  0.877054  0.999912   \n",
       "3         TF-IDF, LogisticRegression, 25000 features  0.877850  0.999867   \n",
       "4  CountVectorizer, LogisticRegression, 5000 feat...  0.882092  0.999779   \n",
       "2          TF-IDF, LogisticRegression, 5000 features  0.930440  0.999912   \n",
       "\n",
       "               cv_time  \n",
       "5            66.415444  \n",
       "0             too much  \n",
       "6  less than 3 minutes  \n",
       "1  less than 3 minutes  \n",
       "7             too much  \n",
       "3             67.56907  \n",
       "4            11.379509  \n",
       "2             9.692238  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(easy_to_look_at_table).sort_values('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb43376",
   "metadata": {},
   "source": [
    "The TF-IDF + Logistic Regression approach is the fastest and, clearly, the most successful one. I hope I will never have to train boosting model on homogeneous data ever again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
