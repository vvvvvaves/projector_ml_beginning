{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMms33J4jeDZ"
   },
   "source": [
    "1. Use any binary classification dataset\n",
    "2. Define validation strategy and use it for all next steps without changes\n",
    "3. Train decision tree model and estimate performance on validation\n",
    "4. Train bagging model with decision tree as a base model and estimate performance on validation\n",
    "5. Write your own bagging implementation:\n",
    "  <br>5.1. Define init for our CustomBaggingClassifier\n",
    "  <br>5.2. Write fit as described in lecture: divide train data on n parts (`n_estimators` in CustomBaggingClassifier), train `base_estimator` on each part and save these models inside class\n",
    "  <br>5.3. For predictions we should use all saved models and combine their predictions (as voting)\n",
    "6. Compare performance of sklearn bagging model with your own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/spaceship_titanic_train.csv')\n",
    "test = pd.read_csv('../data/spaceship_titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, do_1hot=True):\n",
    "    group_count = lambda id_: id_[:4]\n",
    "    data['travel_group'] = data['PassengerId'].apply(lambda id_: id_[:4])\n",
    "    data['travel_group_n'] = data['travel_group'].apply(lambda group: data.loc[data.travel_group == group].shape[0])\n",
    "    data['travelling_with_n_kids'] = (-1)*(train['Age'] < 18).astype(int)+ data['travel_group'].apply(lambda group: data.loc[(data.travel_group == group) & (data.Age < 18)].shape[0])\n",
    "    data['cabin_side'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else str(cabin)[-1])\n",
    "    data['cabin_deck'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else str(cabin)[0])\n",
    "    data['cabin_num'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else int(str(cabin)[2:-2]))\n",
    "    \n",
    "    \n",
    "    drop_ = ['PassengerId','Name', 'Cabin', 'travel_group']\n",
    "    cat = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Transported', 'cabin_side', 'cabin_deck']\n",
    "    num = ['FoodCourt', 'VRDeck', 'Spa', 'Age', 'RoomService', 'ShoppingMall', 'cabin_num']\n",
    "    one_hot = OneHotEncoder(sparse_output=False, drop='if_binary')\n",
    "   \n",
    "    if do_1hot:\n",
    "        pipe = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent'),\n",
    "        one_hot)\n",
    "    else:\n",
    "        pipe = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent'),\n",
    "        OrdinalEncoder())\n",
    "    \n",
    "    transformer = ColumnTransformer([\n",
    "        ('cat', pipe, cat),\n",
    "        ('num', SimpleImputer(strategy='mean'), num),\n",
    "        ('drop_', 'drop', drop_)\n",
    "    ], remainder='passthrough',\n",
    "       verbose_feature_names_out=False)\n",
    "\n",
    "    \n",
    "    d = transformer.fit_transform(data)\n",
    "    if do_1hot:\n",
    "        df = pd.DataFrame(d, columns = transformer.get_feature_names_out(), dtype=float)\n",
    "    else:\n",
    "        df = pd.DataFrame(d, columns = transformer.get_feature_names_out())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = prepare_data(train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_prep.drop('Transported_True', axis=1), train_prep.Transported_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.24140+0.00109\ttest-error:0.25020+0.00579\n",
      "[10]\ttrain-error:0.18981+0.00140\ttest-error:0.20821+0.00452\n",
      "[20]\ttrain-error:0.18115+0.00137\ttest-error:0.20246+0.00477\n",
      "[30]\ttrain-error:0.17169+0.00144\ttest-error:0.19591+0.00383\n",
      "[40]\ttrain-error:0.16620+0.00193\ttest-error:0.19360+0.00493\n",
      "[50]\ttrain-error:0.16125+0.00164\ttest-error:0.19096+0.00499\n",
      "[60]\ttrain-error:0.15383+0.00171\ttest-error:0.19038+0.00750\n",
      "[70]\ttrain-error:0.14960+0.00188\ttest-error:0.18946+0.00611\n",
      "[74]\ttrain-error:0.14851+0.00176\ttest-error:0.18877+0.00493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train-error-mean    0.848240\n",
       "test-error-mean     0.811689\n",
       "Name: 64, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    #default\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eta\": 0.1,\n",
    "    \"verbosity\": 0,\n",
    "    \"nthread\": 4,\n",
    "    \"random_seed\": 1,\n",
    "    \"eval_metric\": \"error\",\n",
    "    #train-error-mean    0.861325\n",
    "    #test-error-mean     0.810883\n",
    "    \n",
    "    #eta = 0.01 test 0.78, train 80.5\n",
    "    \n",
    "    # regularization parameters\n",
    "    \"max_depth\": 5,\n",
    "    \"max_leaves\": 0,\n",
    "    \"min_child_weight\":1,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9\n",
    "    \n",
    "    #train-error-mean    0.848240\n",
    "    #test-error-mean     0.811689\n",
    "    \n",
    "#    \"tree_method\": \"hist\",    \n",
    "#    \"grow_policy\": \"lossguide\"\n",
    "#     train-error-mean    0.827677\n",
    "#     test-error-mean     0.807776\n",
    "}\n",
    "xgb_train = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=127)\n",
    "result = xgb.cv(params, xgb_train, folds =skf, num_boost_round=10_000, early_stopping_rounds=10, verbose_eval=10)\n",
    "1-result.iloc[-1, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep_ = prepare_data(train, do_1hot = False)\n",
    "train__X, train__y = train_prep_.drop('Transported', axis=1), train_prep_.Transported\n",
    "lgb_train = lgb.Dataset(train__X, label=train__y, \n",
    "                        categorical_feature=['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'cabin_side', 'cabin_deck'],\n",
    "                        free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tcv_agg's train binary_error: 0.191821 + 0.00309633\tcv_agg's valid binary_error: 0.205683 + 0.00371206\n",
      "[20]\tcv_agg's train binary_error: 0.183596 + 0.00118703\tcv_agg's valid binary_error: 0.19924 + 0.00403496\n",
      "[30]\tcv_agg's train binary_error: 0.176809 + 0.000542577\tcv_agg's valid binary_error: 0.193949 + 0.00246604\n",
      "[40]\tcv_agg's train binary_error: 0.16913 + 0.0024848\tcv_agg's valid binary_error: 0.192914 + 0.00416128\n",
      "[50]\tcv_agg's train binary_error: 0.162027 + 0.00290216\tcv_agg's valid binary_error: 0.186817 + 0.00433977\n",
      "[60]\tcv_agg's train binary_error: 0.15639 + 0.00269836\tcv_agg's valid binary_error: 0.188427 + 0.00477547\n",
      "Early stopping, best iteration is:\n",
      "[53]\tcv_agg's train binary_error: 0.160762 + 0.00295383\tcv_agg's valid binary_error: 0.186241 + 0.00496277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('train: 0.8392384710701339', 'valid: 0.8137586182024641')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "    #('train: 0.8529852970335823', 'valid: 0.8153695330371873')\n",
    "    \"objective\": \"binary\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"binary_error\",\n",
    "    \"seed\": 42,\n",
    "   \"verbose\":-1,\n",
    "    \n",
    "    #eta 0.01 ('train: 0.8085527468480869', 'valid: 0.7939731642128626')\n",
    "    #eta 0.03 ('train: 0.8322500349942634', 'valid: 0.8069714549649911')\n",
    "    \n",
    "     #regularization\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    #('train: 0.8471183562848146', 'valid: 0.8108826746585971')\n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 60,\n",
    "    #('train: 0.8432359386639986', 'valid: 0.8141035779064327')\n",
    "    \"num_leaves\":20,\n",
    "    #('train: 0.8392384710701339', 'valid: 0.8137586182024641')\n",
    "    \n",
    "    #categorical features\n",
    "#     'cat_smooth': 5,\n",
    "#     'min_data_per_group': 2\n",
    "#     did not improve the results\n",
    "    \n",
    "}\n",
    "lgb_train = lgb.Dataset(train_X, label=train_y, free_raw_data=False)\n",
    "result = lgb.cv(params, lgb_train, 10_000, folds=skf, callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)], eval_train_metric=True)\n",
    "'train: '+str(1-result['train binary_error-mean'][-1]), 'valid: '+str(1-result['valid binary_error-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterations             213.000000\n",
       "train-Accuracy-mean      0.841050\n",
       "test-Accuracy-mean       0.810077\n",
       "Name: 213, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as ctb\n",
    "params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Accuracy\",\n",
    "    \"iterations\": 1000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \"od_wait\": 30,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"thread_count\": 10,\n",
    "    \"logging_level\":\"Silent\",\n",
    "    \n",
    "#     train-Accuracy-mean      0.817439\n",
    "#     test-Accuracy-mean       0.806167\n",
    "    \n",
    "    #regularization\n",
    "    \"depth\":4,\n",
    "#     train-Accuracy-mean      0.814132\n",
    "#     test-Accuracy-mean       0.808697\n",
    "    \"subsample\":0.8,\n",
    "    \"rsm\":0.7,\n",
    "    \"min_data_in_leaf\":50,\n",
    "    \n",
    "    #tree\n",
    "    \"grow_policy\":\"Depthwise\"\n",
    "    \n",
    "#     train-Accuracy-mean      0.841050\n",
    "#     test-Accuracy-mean       0.810077\n",
    "}\n",
    "ctb_train = ctb.Pool(train_X, train_y)\n",
    "result = ctb.cv(ctb_train, params, folds=skf, seed=42, verbose_eval=100,plot=False)\n",
    "result.iloc[-1, [0,3, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prep = prepare_data(test, do_1hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] num_threads is set=10, n_jobs=-1 will be ignored. Current value: num_threads=10\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"binary_error\",\n",
    "    \"seed\": 42,\n",
    "   \"verbose\":-1,\n",
    "    \n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 60,\n",
    "    \"num_leaves\":20\n",
    "    #('train: 0.8392384710701339', 'valid: 0.8137586182024641')\n",
    "}\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(train_X, train_y)\n",
    "preds = lgb_clf.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spaceship_preds_lightgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.80196"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bagging homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
