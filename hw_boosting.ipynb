{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMms33J4jeDZ"
   },
   "source": [
    "1. Use any binary classification dataset\n",
    "2. Define validation strategy and use it for all next steps without changes\n",
    "3. Train decision tree model and estimate performance on validation\n",
    "4. Train bagging model with decision tree as a base model and estimate performance on validation\n",
    "5. Write your own bagging implementation:\n",
    "  <br>5.1. Define init for our CustomBaggingClassifier\n",
    "  <br>5.2. Write fit as described in lecture: divide train data on n parts (`n_estimators` in CustomBaggingClassifier), train `base_estimator` on each part and save these models inside class\n",
    "  <br>5.3. For predictions we should use all saved models and combine their predictions (as voting)\n",
    "6. Compare performance of sklearn bagging model with your own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/spaceship_titanic_train.csv')\n",
    "test = pd.read_csv('../data/spaceship_titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, do_1hot=True):\n",
    "    group_count = lambda id_: id_[:4]\n",
    "    data['travel_group'] = data['PassengerId'].apply(lambda id_: id_[:4])\n",
    "    data['travel_group_n'] = data['travel_group'].apply(lambda group: data.loc[data.travel_group == group].shape[0])\n",
    "    data['travelling_with_n_kids'] = (-1)*(train['Age'] < 18).astype(int)+ data['travel_group'].apply(lambda group: data.loc[(data.travel_group == group) & (data.Age < 18)].shape[0])\n",
    "    data['cabin_side'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else str(cabin)[-1])\n",
    "    data['cabin_deck'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else str(cabin)[0])\n",
    "    data['cabin_num'] = data.Cabin.apply(lambda cabin: np.nan if str(cabin) == 'nan' else int(str(cabin)[2:-2]))\n",
    "    \n",
    "    \n",
    "    drop_ = ['PassengerId','Name', 'Cabin', 'travel_group']\n",
    "    cat = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Transported', 'cabin_side', 'cabin_deck']\n",
    "    num = ['FoodCourt', 'VRDeck', 'Spa', 'Age', 'RoomService', 'ShoppingMall', 'cabin_num']\n",
    "    one_hot = OneHotEncoder(sparse_output=False, drop='if_binary')\n",
    "   \n",
    "    if do_1hot:\n",
    "        pipe = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent'),\n",
    "        one_hot)\n",
    "    else:\n",
    "        pipe = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent'),\n",
    "        OrdinalEncoder())\n",
    "    \n",
    "    transformer = ColumnTransformer([\n",
    "        ('cat', pipe, cat),\n",
    "        ('num', SimpleImputer(strategy='mean'), num),\n",
    "        ('drop_', 'drop', drop_)\n",
    "    ], remainder='passthrough',\n",
    "       verbose_feature_names_out=False)\n",
    "\n",
    "    \n",
    "    d = transformer.fit_transform(data)\n",
    "    if do_1hot:\n",
    "        df = pd.DataFrame(d, columns = transformer.get_feature_names_out(), dtype=float)\n",
    "    else:\n",
    "        df = pd.DataFrame(d, columns = transformer.get_feature_names_out())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = prepare_data(train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_prep.drop('Transported_True', axis=1), train_prep.Transported_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.24140+0.00109\ttest-error:0.25020+0.00579\n",
      "[10]\ttrain-error:0.18981+0.00140\ttest-error:0.20821+0.00452\n",
      "[20]\ttrain-error:0.18115+0.00137\ttest-error:0.20246+0.00477\n",
      "[30]\ttrain-error:0.17169+0.00144\ttest-error:0.19591+0.00383\n",
      "[40]\ttrain-error:0.16620+0.00193\ttest-error:0.19360+0.00493\n",
      "[50]\ttrain-error:0.16125+0.00164\ttest-error:0.19096+0.00499\n",
      "[60]\ttrain-error:0.15383+0.00171\ttest-error:0.19038+0.00750\n",
      "[70]\ttrain-error:0.14960+0.00188\ttest-error:0.18946+0.00611\n",
      "[74]\ttrain-error:0.14851+0.00176\ttest-error:0.18877+0.00493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train-error-mean    0.848240\n",
       "test-error-mean     0.811689\n",
       "Name: 64, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    #default\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eta\": 0.1,\n",
    "    \"verbosity\": 0,\n",
    "    \"nthread\": 4,\n",
    "    \"random_seed\": 1,\n",
    "    \"eval_metric\": \"error\",\n",
    "    #train-error-mean    0.861325\n",
    "    #test-error-mean     0.810883\n",
    "    \n",
    "    #eta = 0.01 test 0.78, train 80.5\n",
    "    \n",
    "    # regularization parameters\n",
    "    \"max_depth\": 5,\n",
    "    \"max_leaves\": 0,\n",
    "    \"min_child_weight\":1,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"n_estimators\": 10_000\n",
    "    \n",
    "    #train-error-mean    0.848240\n",
    "    #test-error-mean     0.811689\n",
    "    \n",
    "#    \"tree_method\": \"hist\",    \n",
    "#    \"grow_policy\": \"lossguide\"\n",
    "#     train-error-mean    0.827677\n",
    "#     test-error-mean     0.807776\n",
    "}\n",
    "xgb_train = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=127)\n",
    "result = xgb.cv(xgb_params, xgb_train, folds =skf, num_boost_round=10_000, early_stopping_rounds=10, verbose_eval=10)\n",
    "xgb_params['n_estimators'] = list(result['test-error-mean']).index(min(list(result['test-error-mean'])))\n",
    "1-result.iloc[-1, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\machine_learning_projector\\venv\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tcv_agg's train binary_error: 0.191821 + 0.00309633\tcv_agg's valid binary_error: 0.205683 + 0.00371206\n",
      "[20]\tcv_agg's train binary_error: 0.183596 + 0.00118703\tcv_agg's valid binary_error: 0.19924 + 0.00403496\n",
      "[30]\tcv_agg's train binary_error: 0.176809 + 0.000542577\tcv_agg's valid binary_error: 0.193949 + 0.00246604\n",
      "[40]\tcv_agg's train binary_error: 0.16913 + 0.0024848\tcv_agg's valid binary_error: 0.192914 + 0.00416128\n",
      "[50]\tcv_agg's train binary_error: 0.162027 + 0.00290216\tcv_agg's valid binary_error: 0.186817 + 0.00433977\n",
      "[60]\tcv_agg's train binary_error: 0.15639 + 0.00269836\tcv_agg's valid binary_error: 0.188427 + 0.00477547\n",
      "Early stopping, best iteration is:\n",
      "[53]\tcv_agg's train binary_error: 0.160762 + 0.00295383\tcv_agg's valid binary_error: 0.186241 + 0.00496277\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "    #('train: 0.8529852970335823', 'valid: 0.8153695330371873')\n",
    "    \"objective\": \"binary\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_threads\": 10,\n",
    "    \"metric\": \"binary_error\",\n",
    "    \"seed\": 42,\n",
    "   \"verbose\":-1,\n",
    "    \n",
    "    #eta 0.01 ('train: 0.8085527468480869', 'valid: 0.7939731642128626')\n",
    "    #eta 0.03 ('train: 0.8322500349942634', 'valid: 0.8069714549649911')\n",
    "    \n",
    "     #regularization\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    #('train: 0.8471183562848146', 'valid: 0.8108826746585971')\n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_data_in_leaf\": 60,\n",
    "    #('train: 0.8432359386639986', 'valid: 0.8141035779064327')\n",
    "    \"num_leaves\":20,\n",
    "    #('train: 0.8392384710701339', 'valid: 0.8137586182024641')\n",
    "    \n",
    "    \"n_estimators\":10_000\n",
    "    \n",
    "    #categorical features\n",
    "#     'cat_smooth': 5,\n",
    "#     'min_data_per_group': 2\n",
    "#     did not improve the results\n",
    "    \n",
    "}\n",
    "lgb_train = lgb.Dataset(train_X, label=train_y, free_raw_data=False)\n",
    "result = lgb.cv(lgb_params, lgb_train, 10_000, folds=skf, callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)], eval_train_metric=True, return_cvbooster=True)\n",
    "lgb_params['n_estimators'] = result[\"cvbooster\"].best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as ctb\n",
    "ctb_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Accuracy\",\n",
    "    \"iterations\": 1000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \"od_wait\": 30,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"thread_count\": 10,\n",
    "    \"logging_level\":\"Silent\",\n",
    "    \n",
    "#     train-Accuracy-mean      0.817439\n",
    "#     test-Accuracy-mean       0.806167\n",
    "    \n",
    "    #regularization\n",
    "    \"depth\":4,\n",
    "#     train-Accuracy-mean      0.814132\n",
    "#     test-Accuracy-mean       0.808697\n",
    "    \"subsample\":0.8,\n",
    "    \"rsm\":0.7,\n",
    "    \"min_data_in_leaf\":50,\n",
    "    \n",
    "    #tree\n",
    "    \"grow_policy\":\"Depthwise\"\n",
    "    \n",
    "#     train-Accuracy-mean      0.841050\n",
    "#     test-Accuracy-mean       0.810077\n",
    "}\n",
    "ctb_train = ctb.Pool(train_X, train_y)\n",
    "result = ctb.cv(ctb_train, ctb_params, folds=skf, seed=42, verbose_eval=100,plot=False)\n",
    "# result.iloc[-1, [0,3, 1]]\n",
    "ctb_params['iterations'] = result.iloc[-1,0]\n",
    "result.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prep = prepare_data(test, do_1hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_clf.fit(train_X, train_y)\n",
    "preds = lgb_clf.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spaceship_preds_lightgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle LIghtGBM score: 0.80196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score on LightGBM after specifying optimal n_iter: 0.80476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(**xgb_params)\n",
    "xgb_clf.fit(train_X, train_y)\n",
    "preds = xgb_clf.predict(test_prep)\n",
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)\n",
    "df.to_csv('spaceship_preds_xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle XGBoost Score: 0.80804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb_clf = ctb.CatBoostClassifier(**ctb_params)\n",
    "ctb_clf.fit(train_X, train_y)\n",
    "preds = ctb_clf.predict(test_prep)\n",
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)\n",
    "df.to_csv('spaceship_preds_ctb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost: 0.8036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "                        max_depth=10, max_leaf_nodes=50, min_samples_leaf=30)\n",
    "tree.fit(train_X, train_y)\n",
    "preds = tree.predict(test_prep)\n",
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)\n",
    "df.to_csv('spaceship_preds_tree.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree score: 0.787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "class CustomBaggingClassifier:\n",
    "    \n",
    "    def __init__(self, base_estimator=DecisionTreeClassifier(), n_estimators=10, max_samples=0.9, max_features=0.7, random_state=127):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        X.reset_index(inplace=True, drop=True)\n",
    "        y.reset_index(inplace=True, drop=True)\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.bag = []\n",
    "        features = X.columns\n",
    "        n_rows = X.shape[0]\n",
    "        self.max_samples = self.max_samples if (self.max_samples % 1 == 0) else max(1, int(self.max_samples*n_rows))\n",
    "        self.max_features = self.max_features if (self.max_features % 1 == 0) else max(1, int(self.max_features*len(features)))\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            bootstrap_set = X.sample(n=self.max_samples, replace=True, axis='index', random_state=(self.random_state+i)).sample(n=self.max_features, replace=False, axis='columns', random_state=(self.random_state+i))\n",
    "            bootstrap_y = y.iloc[bootstrap_set.index]\n",
    "            #\n",
    "            bootstrap_set.reset_index(inplace=True, drop=True)\n",
    "            bootstrap_y.reset_index(inplace=True, drop=True)\n",
    "            #\n",
    "            ith_estimator = clone(self.base_estimator)\n",
    "            ith_estimator.fit(bootstrap_set, bootstrap_y)\n",
    "            self.bag+=[ith_estimator]   \n",
    "        return  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        preds = np.zeros((X.shape[0], self.n_classes))\n",
    "        for estimator in self.bag:\n",
    "            X_seen_features = X[estimator.feature_names_in_]\n",
    "            preds += estimator.predict_proba(X_seen_features)\n",
    "       # f = lambda p: 1 if p/self.n_estimators > 0.5 else 0\n",
    "        f = lambda a: np.argmax(a, axis=1)\n",
    "       # activate = np.vectorize(f)\n",
    "       # return activate(preds)\n",
    "        return f(preds)\n",
    "     \n",
    "    def look_up_importances(self):\n",
    "        i = 1\n",
    "        for estimator in self.bag:\n",
    "            importances = list(zip(estimator.feature_names_in_,estimator.feature_importances_))\n",
    "            importances.sort(key=lambda x: x[1], reverse=True)\n",
    "            print('estimator: ' + str(i))\n",
    "            for im in importances:\n",
    "                print(im)\n",
    "            i+=1    \n",
    "            print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bag = CustomBaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                              criterion='entropy',\n",
    "                                                              max_depth=10,\n",
    "                                                              max_leaf_nodes=50,\n",
    "                                                              min_samples_leaf=30),\n",
    "                        max_features=20, max_samples=6085, n_estimators=15)\n",
    "custom_bag.fit(train_X, train_y)\n",
    "preds = custom_bag.predict(test_prep)\n",
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)\n",
    "df.to_csv('spaceship_preds_custom_bag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Bagging Score: 0.79144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                   criterion='entropy',\n",
    "                                                   max_depth=10,\n",
    "                                                   max_leaf_nodes=50,\n",
    "                                                   min_samples_leaf=30),\n",
    "                  max_features=0.8, max_samples=0.8, n_estimators=8,\n",
    "                  random_state=127)\n",
    "bag_clf.fit(train_X, train_y)\n",
    "preds = bag_clf.predict(test_prep)\n",
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)\n",
    "df.to_csv('spaceship_preds_bag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Score: 0.79705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
    "                        max_depth=15, max_samples=0.9, min_samples_leaf=10,\n",
    "                        n_estimators=15, random_state=42)\n",
    "forest_clf.fit(train_X, train_y)\n",
    "preds = forest_clf.predict(test_prep)\n",
    "df = pd.DataFrame()\n",
    "df['Transported'] = preds.astype(bool)\n",
    "df.set_index(test.PassengerId, inplace=True)\n",
    "df.to_csv('spaceship_preds_forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest: 0.79798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bagging homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
